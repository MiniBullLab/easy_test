Easy SINGRAY-AI整体功能测试
==================

## 测试概述

### 目的
测试上下位机的整体流程通畅。

### 测试范围
测试涉及EasyAnnotation（1.5.0）, ai_runtime（0.1）, EasyGPT（1.5.0）的整体测试。

### 测试流程
#### 1. 安装软件
EasyAnnotation安装：exe安装，按照界面操作提示安装。

ai_runtime安装：
- [easyai安装说明书-docker版](../客户文档/安装使用文档/easyai安装说明书(docker安装版).md)
- [easyai安装说明书-非docker版](../客户文档/安装使用文档/easyai安装说明书(非docker安装版).md)

EasyGPT安装：exe安装，根据边辕视觉用户手册EasyGPT-User-Manual_CN_v1.4.0-release_20200608.pdf进行安装，用户手册存放在百度网盘/参考资料/边辕视觉下面。
#### 2. 软件使用方法
1. 需要使用EasyAnnotation软件，可参照教学视频进行操作。
2. 需要使用ai_runtime训练，可参照如下步骤：
    - classnet训练:
    ```dotnetcli
    1. 打开scripts目录，运行data_dir_create.sh创建easy_data目录
    2. 运行Reset.sh清除log文件
    3. 下载相应数据，将数据下的JPEGImages拷贝到easy_data目录下
    4. 运行ClassNET_tool.sh文件进行训练，classnet.bin文件保存在当前目录下
    5. 删除easy_data目录
    ```
    - denet训练
    ```dotnetcli
    1. 打开scripts目录，运行data_dir_create.sh创建easy_data目录
    2. 运行Reset.sh清除log文件
    3. 下载相应数据，将数据下的Annotations，JPEGImages拷贝到easy_data目录下
    4. 运行DeNET_tool.sh文件进行训练，denet.bin文件保存在当前目录下
    5. 删除easy_data目录
    ```
    - segnet训练
    ```dotnetcli
    1. 打开scripts目录，运行data_dir_create.sh创建easy_data目录
    2. 运行Reset.sh清除log文件
    3. 下载相应数据，将数据下的JPEGImages，SegmentLabel拷贝到easy_data目录下
    4. 运行SegNET_tool.sh文件进行训练，classnet.bin文件保存在当前目录下
    5. 删除easy_data目录
    ```
3. 需要使用EasyGPT软件，可参照[EasyGPT使用及测试](../测试文档/EasyGPT使用及测试.md)

## 测试计划执行情况

### 测试环境与配置

| 资源名称 | 配置 | 备注 |
| :------: | :------ | :------ | 
| PC机器 | windows10,4T硬盘,32G内存,4G独显 | |
| 带有gpu的服务器 | Ubuntu18.04,4T硬盘,128G内存,12G独显 | |
| 安霸cv22芯片 | linux系统内核4.6，RAM2G，ROM8G | |

### 测试用例表格

| 测试用例标识符 | 测试用例名称 | 详细说明 | 备注 |
| :------: | :------ | :------ |  :------ | 
| case001 | PC端ClassNet训练 | 训练数据集为[花朵数据](http://118.31.19.101:8080/dataset/cls/classnet_flower_2class.zip)（2类，混合格式（jpg,png,bmp）），PC端使用ai_runtime(0.1)环境进行ClassNet训练，结果通过easyGPT(1.5.0)的[ClassNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/ClassNet-readfile.gpt)进行HDMI显示测试，类别的结果以文字方式显示在左上角，显示的类别应与图片物体类别一致。| |
| case002 | PC端ClassNet训练 | 训练数据集为[花朵数据](http://118.31.19.101:8080/dataset/cls/classnet_flower_17class_jpg.zip)（17类，jpg格式），PC端使用ai_runtime(0.1)环境进行classnet训练，结果通过easyGPT(1.5.0)的[ClassNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/ClassNet-readfile.gpt)进行HDMI显示测试，类别的结果以文字方式显示在左上角，显示的类别应与图片物体类别一致。| |
| case003 | AWS云端ClassNet训练 | 训练数据集为[花朵数据](http://118.31.19.101:8080/dataset/cls/classnet_flower_2class.zip)（2类，混合格式（jpg,png,bmp）），AWS云端使用ai_runtime(0.1)环境进行ClassNet训练，结果通过easyGPT(1.5.0)的[ClassNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/ClassNet-readfile.gpt)进行HDMI显示测试，类别的结果以文字方式显示在左上角，显示的类别应与图片物体类别一致。| |
| case004 | AWS云端ClassNet训练 | 训练数据集为[花朵数据](http://118.31.19.101:8080/dataset/cls/classnet_flower_17class_jpg.zip)（17类，jpg格式），AWS云端使用ai_runtime(0.1)环境进行ClassNet训练，结果通过easyGPT(1.5.0)的[ClassNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/ClassNet-readfile.gpt)进行HDMI显示测试，类别的结果以文字方式显示在左上角，显示的类别应与图片物体类别一致。| |
| case005 | PC端DeNet训练 | 训练数据集为[水果数据](http://118.31.19.101:8080/dataset/det/denet_fruit_4class.zip)（4类，混合格式（jpg,png,bmp）），PC端使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case006 | PC端DeNet训练 | 训练数据集为[Berkeley数据](http://118.31.19.101:8080/dataset/det/denet_berkeley_10class_jpg.zip)（10类，jpg格式），PC端使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case007 | AWS云端DeNet训练 | 训练数据集为[水果数据](http://118.31.19.101:8080/dataset/det/denet_fruit_4class.zip)（4类，混合格式（jpg,png,bmp）），AWS云端使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case008 | AWS云端DeNet训练 | 训练数据集为[Berkeley数据](http://118.31.19.101:8080/dataset/det/denet_berkeley_10class_jpg.zip)（10类，jpg格式），AWS云端使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case009 | PC端DeNet标注及训练 | 训练数据集为[汽车模型数据](http://118.31.19.101:8080/dataset/det/denet_car_2class_jpg.zip)（2类，jpg格式），PC端使用EasyAnnotation(1.5.0)进行汽车模型数据标注，使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case010 | PC端DeNet标注转换及训练 | 训练数据集为[饺子数据](http://118.31.19.101:8080/dataset/det/denet_dumpling_1class_bmp_xml.zip)（1类，jpg格式），标注结果为xml格式，PC端使用EasyAnnotation(1.5.0)进行饺子数据转换，使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case011 | AWS云端DeNet标注及训练 | 训练数据集为[汽车模型数据](http://118.31.19.101:8080/dataset/det/denet_berkeley_10class_jpg.zip)（2类，jpg格式），AWS云端使用EasyAnnotation(1.5.0)进行汽车模型数据标注，使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case012 | AWS云端DeNet标注转换及训练 | 训练数据集为[饺子数据](http://118.31.19.101:8080/dataset/det/denet_dumpling_1class_bmp_xml.zip)（1类，jpg格式），标注结果为xml格式，AWS云端使用EasyAnnotation(1.5.0)进行饺子数据转换，使用ai_runtime(0.1)环境进行DeNet训练，结果通过easyGPT(1.5.0)的[DeNet-readfile.gpt](http://118.31.19.101:8080/easy_gpt/DeNet-readfile.gpt)进行HDMI显示测试，结果通过不同颜色的框将物体框住，并且在框的上方会显示类别的文字，显示的类别应与所框住的物体类别一致。| |
| case013 | PC端SegNet训练 | 训练数据集为[螺母数据](http://118.31.19.101:8080/dataset/seg/segnet_nut_2class.zip)（2类，混合格式（jpg,png,bmp）），PC端使用ai_runtime(0.1)环境进行SegNet训练，结果通过easyGPT(1.5.0)的[SegNet-readfile_1280X960.gpt](http://118.31.19.101:8080/easy_gpt/SegNet-readfile_1280X960.gpt)进行HDMI显示测试，显示结果为缺陷结果叠加到原图上，并在右侧显示分割图的结果。|  |
| case014 | AWS云端SegNet训练 | 训练数据集为[螺母数据](http://118.31.19.101:8080/dataset/seg/segnet_nut_2class.zip)（2类，混合格式（jpg,png,bmp）），AWS云端使用ai_runtime(0.1)环境进行SegNet训练，结果通过easyGPT(1.5.0)的[SegNet-readfile_1280X960.gpt](http://118.31.19.101:8080/easy_gpt/SegNet-readfile_1280X960.gpt)进行HDMI显示测试，显示结果为缺陷结果叠加到原图上，并在右侧显示分割图的结果。|  |
| case015 | PC端SegNet标注及训练 | 训练数据集为[易拉罐底部气泡数据](http://118.31.19.101:8080/dataset/seg/segnet_can_2class_jpg.zip)（2类，jpg格式），PC端使用EasyAnnotation(1.5.0)进行易拉罐底部气泡数据标注，PC端使用ai_runtime(0.1)环境进行segnet训练，结果通过easyGPT(1.5.0)的[SegNet-readfile_2432X2048.gpt](http://118.31.19.101:8080/easy_gpt/SegNet-readfile_2432X2048.gpt)进行HDMI显示测试，显示结果为缺陷结果叠加到原图上，并在右侧显示分割图的结果。|  |
| case016 | PC端SegNet标注非标准格式训练 | 训练数据集为[LED划痕数据](http://118.31.19.101:8080/dataset/seg/segnet_led_2class_wrong_label.zip)（2类，混合格式（jpg,png,bmp,jpeg）），标注分割图为500X400大小的混合格式，PC端使用ai_runtime(0.1)环境进行segnet训练，结果通过easyGPT(1.5.0)的[SegNet-readfile_440X512.gpt](http://118.31.19.101:8080/easy_gpt/SegNet-readfile_440X512.gpt)进行HDMI显示测试，显示结果为缺陷结果叠加到原图上，并在右侧显示分割图的结果。|  |
| case017 | AWS云端SegNet标注及训练 | 训练数据集为[易拉罐底部气泡数据](http://118.31.19.101:8080/dataset/seg/segnet_can_2class_jpg.zip)（2类，jpg格式），PC端使用EasyAnnotation(1.5.0)进行易拉罐底部气泡数据标注，AWS云端使用ai_runtime(0.1)环境进行SegNet训练，结果通过easyGPT(1.5.0)的[SegNet-readfile_2432X2048.gpt](http://118.31.19.101:8080/easy_gpt/SegNet-readfile_2432X2048.gpt)进行HDMI显示测试，显示结果为缺陷结果叠加到原图上，并在右侧显示分割图的结果。|  |
| case018 | AWS云端SegNet标注非标准格式训练 | 训练数据集为[LED划痕数据](http://118.31.19.101:8080/dataset/seg/segnet_led_2class_wrong_label.zip)（2类，混合格式（jpg,png,bmp,jpeg）），标注分割图为500X400大小的混合格式，AWS云端使用ai_runtime(0.1)环境进行SegNet训练，结果通过easyGPT(1.5.0)的[SegNet-readfile_440X512.gpt](http://118.31.19.101:8080/easy_gpt/SegNet-readfile_440X512.gpt)进行HDMI显示测试，显示结果为缺陷结果叠加到原图上，并在右侧显示分割图的结果。|  |

